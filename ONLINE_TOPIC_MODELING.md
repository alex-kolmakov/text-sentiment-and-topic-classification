# Online Topic Modeling: Evolution from Static Alignment

This document explains how to evolve from manually predefined topics to automated topic discovery approaches.

---

## Current Approach: Static Alignment

**How it works:**
1. Manually define topics with keyword descriptions (Hardware Issues, Network Configuration, etc.)
2. BERTopic discovers topics from data
3. Align discovered topics to predefined categories using cosine similarity

**Pros:** Consistent categories, clear names, easy tracking  
**Cons:** Manual effort, can't adapt to new patterns, requires domain expertise

---

## Approach 1: Pure Discovery

**Concept:** Remove predefined topics entirely. Use BERTopic's discovered topics directly.

**Implementation:**
```python
topic_model = BERTopic(nr_topics="auto")
topics, _ = topic_model.fit_transform(conversations)
# Auto-generate labels like "network, wifi, connection"
```

**Pros:** Zero manual work, finds unexpected patterns, adapts to any dataset  
**Cons:** Topics change every run, generic labels, hard to track over time

---

## Approach 2: Semi-Supervised

**Concept:** Provide example conversations (not keywords) to guide topic formation.

**Implementation:**
```python
seed_topics = [
    ["Printer won't print", "USB mouse not detected", ...],  # Hardware
    ["Can't connect to wifi", "DNS not working", ...],       # Network
]
topic_model = BERTopic(seed_topic_list=seed_topics)
```

**Pros:** Natural examples, flexible matching, easier to curate than keywords  
**Cons:** Still requires manual examples, seed quality matters

---

## Approach 3: Hierarchical

**Concept:** Discover fine-grained topics, then automatically cluster into high-level categories.

**Implementation:**
```python
# Step 1: Discover many fine-grained topics
topic_model = BERTopic(min_topic_size=50, nr_topics="auto")
topics, _ = topic_model.fit_transform(conversations)

# Step 2: Cluster topics into categories
from sklearn.cluster import AgglomerativeClustering
category_model = AgglomerativeClustering(n_clusters=8)
categories = category_model.fit_predict(topic_embeddings)
# Creates: Topic â†’ Category hierarchy automatically
```

**Pros:** Fully automatic, natural hierarchy, scalable  
**Cons:** Category names need interpretation, less stable

---

## Approach 4: Incremental Learning

**Concept:** Train initial model, then update incrementally as new data arrives.

**Implementation:**
```python
# Initial training
model = BERTopic()
model.fit_transform(historical_conversations)

# Daily updates
model.partial_fit(new_conversations)

# Weekly consolidation
model.reduce_topics(all_conversations, nr_topics="auto")
```

**Pros:** Adapts to new patterns, efficient, no full retraining  
**Cons:** Topic drift over time, version management complexity  

---

## Approach 5: Hybrid (Probably the best)

**Concept:** Start with discovery, evolve to semi-supervised, maintain with incremental updates.

**Phases:**
1. **Months 1-3:** Pure discovery to understand data
2. **Month 4:** Manual review and create representative documents
3. **Months 5-12:** Semi-supervised operation with monthly reviews
4. **Ongoing:** Incremental updates + quarterly retraining

**Pros:** Best of all approaches, data-informed, maintainable  
**Cons:** Complex workflow, requires ongoing effort  